<head>
    <!-- <link rel="stylesheet" href="../../tailwind-css/tailwind-runtime.css" /> -->
    <!-- <link rel="stylesheet" href="../../tailwind-css/tailwind-build.css" /> -->
    <link rel="stylesheet" href="css/card.css" />
</head>

<div style="font-size:2rem; font-weight:bold;
            max-width:900px; margin:16px auto 16px;">
    Projects I've Worked On
</div>

<!-- Medical Chatbot with MLOps Deployment Pipeline -->
<a
    href="https://github.com/phoenix1881/Medical-Chatbot-MLOps"
    target="_blank"
    style="
        display: block;
        width: 100%;
        max-width: 900px;
        margin: 32px auto;
        background: #fff;
        border-radius: 18px;
        box-shadow: 0 4px 24px rgba(0,0,0,0.08);
        padding: 32px 40px;
        text-decoration: none;
        color: #222;
        transition: box-shadow 0.2s;
    "
    onmouseover="this.style.boxShadow='0 8px 32px rgba(0,0,0,0.16)'"
    onmouseout="this.style.boxShadow='0 4px 24px rgba(0,0,0,0.08)'"
>
    <h2 style="font-size: 2rem; font-weight: bold; margin-bottom: 18px;">
        Medical Chatbot with MLOps Deployment Pipeline
    </h2>
    <div style="margin-bottom: 16px;">
        <strong>Summary:</strong>
        <ul style="margin: 8px 0 0 18px;">
            <li>Fine-tuned TinyLLaMa 1.1M model for healthcare Q&A.</li>
            <li>Fully containerized and production-ready with monitoring and CI/CD.</li>
        </ul>
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Technologies Used:</strong> FastAPI, Docker, MLflow, Prometheus, Grafana, Locust, CI/CD tools, TinyLLaMa.
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Details:</strong><br>
        This project builds a robust medical chatbot capable of responding to patient queries across diverse clinical intents. It’s architected for modularity—allowing seamless model upgrades—while providing reliability through Docker containerization and FastAPI serving. MLflow tracks experiments, while Prometheus and Grafana monitor latency and resource use in real time. Locust stress-tests the service under concurrent load, and CI/CD hooks ensure continuous improvement.
    </div>
    <span style="color: #2563eb; font-weight: 600;">View on GitHub</span>
</a>

<!-- Label-Efficient Steering Control with I-JEPA -->
<a
    href="https://github.com/phoenix1881/Predictive-Steering-with-I-JEPA"
    target="_blank"
    style="
        display: block;
        width: 100%;
        max-width: 900px;
        margin: 32px auto;
        background: #fff;
        border-radius: 18px;
        box-shadow: 0 4px 24px rgba(0,0,0,0.08);
        padding: 32px 40px;
        text-decoration: none;
        color: #222;
        transition: box-shadow 0.2s;
    "
    onmouseover="this.style.boxShadow='0 8px 32px rgba(0,0,0,0.16)'"
    onmouseout="this.style.boxShadow='0 4px 24px rgba(0,0,0,0.08)'"
>
    <h2 style="font-size: 2rem; font-weight: bold; margin-bottom: 18px;">
        Label-Efficient Steering Control with I-JEPA
    </h2>
    <div style="margin-bottom: 16px;">
        <strong>Summary:</strong>
        <ul style="margin: 8px 0 0 18px;">
            <li>Self-supervised ViT model pretrained on unlabeled frames.</li>
            <li>Fine-tuned on minimal labeled data; excellent performance in steering prediction.</li>
        </ul>
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Technologies Used:</strong> PyTorch, CARLA, Vision Transformers (timm), EMA teacher-student, cosine & variance loss, NYU Greene HPC (A100/V100 GPUs).
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Details:</strong><br>
        A deep dive into label-efficient learning for autonomous driving using I-JEPA. Pretrained on ~86K unlabeled CARLA frames, the model was fine-tuned using only 5–11% labeled data. I addressed the rare-turn vs. straight-driving imbalance via balanced sampling and achieved a striking validation MSE of 0.0018—outperforming fully supervised baselines. All experiments ran on NYU’s HPC infrastructure with efficient job scheduling and model checkpointing.
    </div>
    <span style="color: #2563eb; font-weight: 600;">View on GitHub</span>
</a>

<!-- CIFAR-10 Image Classification -->
<a
    href="https://github.com/phoenix1881/ECE-GY-7123-DL"
    target="_blank"
    style="
        display: block;
        width: 100%;
        max-width: 900px;
        margin: 32px auto;
        background: #fff;
        border-radius: 18px;
        box-shadow: 0 4px 24px rgba(0,0,0,0.08);
        padding: 32px 40px;
        text-decoration: none;
        color: #222;
        transition: box-shadow 0.2s;
    "
    onmouseover="this.style.boxShadow='0 8px 32px rgba(0,0,0,0.16)'"
    onmouseout="this.style.boxShadow='0 4px 24px rgba(0,0,0,0.08)'"
>
    <h2 style="font-size: 2rem; font-weight: bold; margin-bottom: 18px;">
        CIFAR-10 Image Classification
    </h2>
    <div style="margin-bottom: 16px;">
        <strong>Summary:</strong>
        <ul style="margin: 8px 0 0 18px;">
            <li>Explored custom CNN, ResNet-18, and Vision Transformer architectures.</li>
            <li>Achieved ~91% accuracy with strong augmentation and visualization tools.</li>
        </ul>
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Technologies Used:</strong> PyTorch, torchvision, NumPy, Matplotlib, seaborn, Grad-CAM.
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Details:</strong><br>
        This project evaluated multiple deep learning architectures on CIFAR-10, blending rigorous data augmentation with detailed visual analysis (loss plots, confusion matrices, and Grad-CAM attention maps). ResNet-18 with well-tuned augmentation and regularization reached ~91% test accuracy, showcasing how systematic experimentation pays off.
    </div>
    <span style="color: #2563eb; font-weight: 600;">View on GitHub</span>
</a>

<!-- AGNews Text Classification with LoRA -->
<a
    href="https://github.com/phoenix1881/DL_Project2"
    target="_blank"
    style="
        display: block;
        width: 100%;
        max-width: 900px;
        margin: 32px auto;
        background: #fff;
        border-radius: 18px;
        box-shadow: 0 4px 24px rgba(0,0,0,0.08);
        padding: 32px 40px;
        text-decoration: none;
        color: #222;
        transition: box-shadow 0.2s;
    "
    onmouseover="this.style.boxShadow='0 8px 32px rgba(0,0,0,0.16)'"
    onmouseout="this.style.boxShadow='0 4px 24px rgba(0,0,0,0.08)'"
>
    <h2 style="font-size: 2rem; font-weight: bold; margin-bottom: 18px;">
        AGNews Text Classification with LoRA
    </h2>
    <div style="margin-bottom: 16px;">
        <strong>Summary:</strong>
        <ul style="margin: 8px 0 0 18px;">
            <li>RoBERTa fine-tuned using LoRA under tight parameter budget (~667K params).</li>
            <li>Achieved strong validation accuracy while being resource-efficient.</li>
        </ul>
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Technologies Used:</strong> Python, HuggingFace Transformers, PEFT, PyTorch.
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Details:</strong><br>
        Focused on parameter-efficient deployment of NLP models, I used LoRA to fine-tune RoBERTa by adjusting only the Q/K attention matrices. With under 1 million trainable parameters, the model achieved 88.42% validation accuracy—demonstrating practical fine-tuning for constrained environments.
    </div>
    <span style="color: #2563eb; font-weight: 600;">View on GitHub</span>
</a>

<!-- Jailbreaking Deep Models — Adversarial Attacks on ImageNet -->
<a
    href="https://github.com/phoenix1881/DL_Project_3"
    target="_blank"
    style="
        display: block;
        width: 100%;
        max-width: 900px;
        margin: 32px auto;
        background: #fff;
        border-radius: 18px;
        box-shadow: 0 4px 24px rgba(0,0,0,0.08);
        padding: 32px 40px;
        text-decoration: none;
        color: #222;
        transition: box-shadow 0.2s;
    "
    onmouseover="this.style.boxShadow='0 8px 32px rgba(0,0,0,0.16)'"
    onmouseout="this.style.boxShadow='0 4px 24px rgba(0,0,0,0.08)'"
>
    <h2 style="font-size: 2rem; font-weight: bold; margin-bottom: 18px;">
        Jailbreaking Deep Models — Adversarial Attacks on ImageNet
    </h2>
    <div style="margin-bottom: 16px;">
        <strong>Summary:</strong>
        <ul style="margin: 8px 0 0 18px;">
            <li>Applied FGSM, PGD, and Patch-PGD adversarial attacks.</li>
            <li>Demonstrated patch attacks’ transferability across models.</li>
        </ul>
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Technologies Used:</strong> PyTorch, torchvision, Foolbox, Matplotlib, NumPy.
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Details:</strong><br>
        This project explores the robustness of ImageNet classifiers under adversarial pressure. Using FGSM, PGD, and Patch-PGD, I attacked ResNet-34 and assessed transferability to DenseNet-121. Results revealed that patch-based attacks could bypass defenses even when pixel-level ones failed, emphasizing deployment risks in real-world systems.
    </div>
    <span style="color: #2563eb; font-weight: 600;">View on GitHub</span>
</a>

<!-- F1 Race Predictor -->
<a
    href="https://github.com/phoenix1881/f1-predictor"
    target="_blank"
    style="
        display: block;
        width: 100%;
        max-width: 900px;
        margin: 32px auto;
        background: #fff;
        border-radius: 18px;
        box-shadow: 0 4px 24px rgba(0,0,0,0.08);
        padding: 32px 40px;
        text-decoration: none;
        color: #222;
        transition: box-shadow 0.2s;
    "
    onmouseover="this.style.boxShadow='0 8px 32px rgba(0,0,0,0.16)'"
    onmouseout="this.style.boxShadow='0 4px 24px rgba(0,0,0,0.08)'"
>
    <h2 style="font-size: 2rem; font-weight: bold; margin-bottom: 18px;">
        F1 Race Predictor
    </h2>
    <div style="margin-bottom: 16px;">
        <strong>Summary:</strong>
        <ul style="margin: 8px 0 0 18px;">
            <li>Full-stack application predicting Formula 1 outcomes.</li>
            <li>Data-driven features with logistic regression and ensemble modeling.</li>
        </ul>
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Technologies Used:</strong> Python, Scikit-learn, Flask, ReactJS, Tailwind CSS.
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Details:</strong><br>
        A predictive platform that takes qualifying data—lap times, grid positions, driver statistics—and predicts race outcomes using various ML models. The backend operates in Flask, while the front end delivers an interactive experience via React and Tailwind. The model leverages cross-validation to enhance prediction reliability.
    </div>
    <span style="color: #2563eb; font-weight: 600;">View on GitHub</span>
</a>

<!-- Person-Following Indoor Robot (Simulation) -->
<a
    href="https://github.com/phoenix1881/robotics_project"
    target="_blank"
    style="
        display: block;
        width: 100%;
        max-width: 900px;
        margin: 32px auto;
        background: #fff;
        border-radius: 18px;
        box-shadow: 0 4px 24px rgba(0,0,0,0.08);
        padding: 32px 40px;
        text-decoration: none;
        color: #222;
        transition: box-shadow 0.2s;
    "
    onmouseover="this.style.boxShadow='0 8px 32px rgba(0,0,0,0.16)'"
    onmouseout="this.style.boxShadow='0 4px 24px rgba(0,0,0,0.08)'"
>
    <h2 style="font-size: 2rem; font-weight: bold; margin-bottom: 18px;">
        Person-Following Indoor Robot (Simulation)
    </h2>
    <div style="margin-bottom: 16px;">
        <strong>Summary:</strong>
        <ul style="margin: 8px 0 0 18px;">
            <li>Simulated robot using wavefront path planning and raycasting.</li>
            <li>Reactive control loop with transition from Pygame to Gazebo.</li>
        </ul>
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Technologies Used:</strong> Pygame, Gazebo, ROS (implied), wavefront planning, raycasting algorithms.
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Details:</strong><br>
        Designed a person-following robot in simulation. Beginning with a Pygame prototype, the project evolved into Gazebo, adding realistic sensor behaviors and physics. Wavefront path planning and raycasting enabled dynamic and modular control in uncluttered and obstacle-laden environments.
    </div>
    <span style="color: #2563eb; font-weight: 600;">View on GitHub</span>
</a>

<!-- OAuth-Based Secure Authentication System -->
<a
    href="https://github.com/phoenix1881/holocron-web"
    target="_blank"
    style="
        display: block;
        width: 100%;
        max-width: 900px;
        margin: 32px auto;
        background: #fff;
        border-radius: 18px;
        box-shadow: 0 4px 24px rgba(0,0,0,0.08);
        padding: 32px 40px;
        text-decoration: none;
        color: #222;
        transition: box-shadow 0.2s;
    "
    onmouseover="this.style.boxShadow='0 8px 32px rgba(0,0,0,0.16)'"
    onmouseout="this.style.boxShadow='0 4px 24px rgba(0,0,0,0.08)'"
>
    <h2 style="font-size: 2rem; font-weight: bold; margin-bottom: 18px;">
        OAuth-Based Secure Authentication System
    </h2>
    <div style="margin-bottom: 16px;">
        <strong>Summary:</strong>
        <ul style="margin: 8px 0 0 18px;">
            <li>Implemented OAuth 2.0 for secure access and refresh token handling.</li>
            <li>Designed session policies with API protection layers.</li>
        </ul>
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Technologies Used:</strong> OAuth 2.0, token lifecycle management, session timeout policies, API authorization.
    </div>
    <div style="margin-bottom: 16px;">
        <strong>Details:</strong><br>
        Built a secure authentication backend using OAuth 2.0 standards. Features include fine-grained session control, robust access and refresh token management, and policy-driven session timeouts. Structured for integration in multi-service platforms prioritizing secure user access.
    </div>
    <span style="color: #2563eb; font-weight: 600;">View on GitHub</span>
</a>