<head>
    <!-- <link rel="stylesheet" href="../../tailwind-css/tailwind-runtime.css" /> -->
    <!-- <link rel="stylesheet" href="../../tailwind-css/tailwind-build.css" /> -->
    <link rel="stylesheet" href="css/card.css" />
</head>

<div>
    I have worked on many projects including but not limited to
</div>

<div class="tw-flex tw-flex-col tw-items-center tw-w-full tw-gap-8 tw-px-8">
    <a class="card-container tw-w-full tw-max-w-4xl tw-cursor-pointer tw-bg-white tw-rounded-xl tw-shadow-lg tw-p-8 tw-transition hover:tw-shadow-2xl"
       href="https://github.com/PaulleDemon/awesome-landing-pages"
       target="_blank"
       style="text-decoration: none;">
        <div class="card-content">
            <h2 class="tw-text-2xl tw-font-bold tw-mb-4">Medical Chatbot with MLOps Deployment Pipeline</h2>
            <div class="tw-mb-4">
                <strong>Summary:</strong><br>
                Fine-tuned TinyLLaMa 1.1M model for healthcare Q&A.<br>
                Fully containerized and production-ready with monitoring and CI/CD.
            </div>
            <div class="tw-mb-4">
                <strong>Technologies Used:</strong> FastAPI, Docker, MLflow, Prometheus, Grafana, Locust, CI/CD tools, TinyLLaMa.
            </div>
            <div class="tw-mb-4">
                <strong>Details:</strong><br>
                This project builds a robust medical chatbot capable of responding to patient queries across diverse clinical intents. It’s architected for modularity—allowing seamless model upgrades—while providing reliability through Docker containerization and FastAPI serving. MLflow tracks experiments, while Prometheus and Grafana monitor latency and resource use in real time. Locust stress-tests the service under concurrent load, and CI/CD hooks ensure continuous improvement.
            </div>
            <span class="tw-text-blue-600 tw-font-semibold">View on GitHub</span>
        </div>
    </a>
</div>